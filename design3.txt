Project Overview
Build a reproducible, Docker-based benchmarking platform that uses a single FastAPI service to serve both backend logic and HTML views enhanced by HTMX, eliminating any separate JavaScript frontend. The platform will:

Ingest a PostgreSQL dump and a list of SQL queries.
Apply different pg_statistics sources (built-in vs. random) to the database.
Run each SQL query for n trials under each stats source, measuring execution time and EXPLAIN cost.
Aggregate results (average, standard deviation) and store both summary and per-trial data.
Serve HTML pages via FastAPI + Jinja2Templates, with HTMX for declarative, AJAX-style interactions (file uploads, experiment launches, result updates, chart swapping), and Matplotlib-generated charts embedded as images.
1. Docker Compose (docker-compose.yml)

version: "3.8"
services:
  postgres:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: experiment
    volumes:
      - ./data/db:/var/lib/postgresql/data
      - ./samples/dump.sql:/docker-entrypoint-initdb.d/dump.sql:ro
    ports:
      - "5432:5432"

  web:
    build: ./app
    depends_on:
      - postgres
    environment:
      DATABASE_URL: postgresql+psycopg2://postgres:postgres@postgres:5432/experiment
    volumes:
      - ./app:/app
      - ./samples/queries.sql:/app/samples/queries.sql:ro
    ports:
      - "8000:8000"
2. Application Structure (./app)

app/
├── Dockerfile
├── alembic/             # (optional) for migrations
├── samples/
│   └── queries.sql
├── app/
│   ├── main.py
│   ├── database.py
│   ├── models.py
│   ├── schemas.py
│   ├── experiment.py
│   ├── stats_sources/
│   │   ├── base.py
│   │   ├── direct_pg.py
│   │   └── random_pg.py
│   ├── routers/
│   │   ├── upload.py
│   │   ├── run.py
│   │   └── results.py
│   ├── templates/
│   │   ├── base.html
│   │   ├── upload.html
│   │   ├── experiment.html
│   │   ├── results.html
│   │   └── _partials/
│   │       ├── _results_table.html
│   │       └── _chart_img.html
│   └── static/
│       └── charts/      # runtime-generated PNGs
├── pyproject.toml
└── poetry.lock
2.1. Dockerfile
FROM python:3.11-slim
WORKDIR /app

# Install dependencies
COPY pyproject.toml poetry.lock ./
RUN pip install poetry \
    && poetry config virtualenvs.create false \
    && poetry install --no-dev

# Copy source
COPY . .

# Expose and run
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
3. Key Components

3.1. database.py
Create SQLAlchemy engine, SessionLocal, Base.
(Optional) Run Alembic migrations on startup.
3.2. models.py
Experiment: id, stats_source, query, iterations, avg_time, stddev_time, created_at.
Trial: id, experiment_id, run_index, execution_time, cost_estimate.
3.3. stats_sources/
base.py: abstract StatsSource with apply_statistics() & name().
direct_pg.py: no-op (uses built-in stats).
random_pg.py: for each column in pg_stats, issue ALTER TABLE … SET STATISTICS with random values.
3.4. experiment.py
ExperimentRunner applies a stats source, executes each SQL query n times, records timers, computes average & standard deviation, and persists both summary and per-trial records.
4. HTMX-powered Routers & Templates

4.1. File Upload (routers/upload.py)
GET /upload → upload.html (form for dump + queries).
POST /upload/dump & /upload/queries → save to disk, return an HTMX fragment (_partials/_upload_status.html) indicating success.
4.2. Experiment Launch (routers/run.py)
GET /experiment → experiment.html (dropdown of stats sources from code introspection, numeric input for iterations).
POST /experiment (htmx request) → kicks off ExperimentRunner, returns a streaming SSE response of progress updates.
GET /experiment/status/{experiment_id} (htmx polling) → returns updated progress bar fragment (_partials/_progress.html) until completion, then swaps in a link to results.
4.3. Results Display (routers/results.py)
GET /results → results.html (table of all experiments).
GET /results/{id}/table (hx-get) → returns _partials/_results_table.html for that experiment.
GET /results/{id}/chart?type=bar|line (hx-get) → returns _partials/_chart_img.html embedding a PNG generated by Matplotlib at static/charts/{id}_{type}.png.
5. Templates & Partial Fragments

base.html
Includes HTMX script. Blocks: head, content, scripts.
upload.html
Two <form hx-post> panels for dump & queries.
Target a <div hx-swap-oob="true" id="upload-status"> for feedback.
experiment.html
<select name="stats_source" multiple> populated server-side.
<input type="number" name="iterations">.
<button hx-post="/experiment" hx-sse="connect:/experiment/stream">Run</button>
<div id="progress" hx-get="/experiment/status/{new_id}" hx-trigger="every 1s"></div>
results.html
Table of experiments; each row has <button hx-get="/results/{id}/table">View Details</button>.
<div id="details"></div> for injecting table.
Chart type toggles: <button hx-get="/results/{id}/chart?type=bar" hx-target="#chart">Bar</button> etc.
<img id="chart" src="/static/charts/{id}_bar.png"> fallback.
Partials in _partials/ return only the fragment to swap (e.g. <table>…</table> or <img …>).
6. Chart Generation

On experiment completion or on-demand, your router invokes a function to:
Query the DB for per-trial times or summary.
Use Matplotlib to plot bar or line charts.
Save PNG under static/charts/{experiment_id}_{type}.png.
HTMX simply swaps in the new <img> at user request—no client-side JS logic needed.
7. Running the Project

Clone repository.
Place your optional samples/dump.sql and samples/queries.sql, or use the upload UI.
From project root, run:
docker-compose up --build
Visit http://localhost:8000/upload to start.
