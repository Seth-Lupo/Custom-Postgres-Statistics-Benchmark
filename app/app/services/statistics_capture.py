"""
PostgreSQL Statistics Estimator - Statistics Capture Service

This module provides functionality for capturing PostgreSQL database statistics
snapshots during experiment trials. It handles both pg_stats and pg_statistic
views to provide comprehensive statistics information.

Classes:
    StatisticsCapture: Manages database statistics snapshot collection

Author: Generated by Assistant
Created: 2024
"""

import json
from typing import Tuple, Dict, List, Any, Optional
from sqlalchemy import text
from sqlmodel import Session
from ..logging_config import stats_logger


class StatisticsCapture:
    """
    Handles capturing database statistics snapshots for experiment trials.
    
    This service manages:
    - pg_stats view snapshot collection
    - pg_statistic view snapshot collection  
    - JSON serialization of statistics data
    - Error handling for statistics queries
    """
    
    def __init__(self):
        """Initialize the statistics capture service."""
        pass
        
    def capture_statistics_snapshots(self, session: Session) -> Tuple[str, str]:
        """
        Capture snapshots of pg_stats and pg_statistic for a trial.
        
        Args:
            session: Database session for executing queries
            
        Returns:
            Tuple containing (pg_stats_json, pg_statistic_json)
            
        Raises:
            Exception: If statistics capture fails
        """
        try:
            pg_stats_data = self._capture_pg_stats(session)
            pg_statistic_data = self._capture_pg_statistic(session)
            
            # Convert to JSON strings
            pg_stats_json = json.dumps(pg_stats_data, default=str, indent=2)
            pg_statistic_json = json.dumps(pg_statistic_data, default=str, indent=2)
            
            stats_logger.debug(f"Captured {len(pg_stats_data)} pg_stats rows and {len(pg_statistic_data)} pg_statistic rows")
            
            return pg_stats_json, pg_statistic_json
            
        except Exception as e:
            stats_logger.error(f"Failed to capture statistics snapshots: {str(e)}")
            raise
            
    def _capture_pg_stats(self, session: Session) -> List[Dict[str, Any]]:
        """
        Capture pg_stats view data for public schema tables.
        
        Args:
            session: Database session for executing queries
            
        Returns:
            List of dictionaries containing pg_stats data
        """
        pg_stats_query = text("""
            SELECT schemaname, tablename, attname, inherited, null_frac, avg_width, n_distinct,
                   most_common_vals, most_common_freqs, histogram_bounds, correlation, 
                   most_common_elems, most_common_elem_freqs, elem_count_histogram
            FROM pg_stats 
            WHERE schemaname = 'public'
            ORDER BY schemaname, tablename, attname
        """)
        
        result = session.execute(pg_stats_query)
        pg_stats_data = []
        
        for row in result:
            pg_stats_data.append({
                'schemaname': row.schemaname,
                'tablename': row.tablename, 
                'attname': row.attname,
                'inherited': row.inherited,
                'null_frac': float(row.null_frac) if row.null_frac is not None else None,
                'avg_width': int(row.avg_width) if row.avg_width is not None else None,
                'n_distinct': float(row.n_distinct) if row.n_distinct is not None else None,
                'most_common_vals': str(row.most_common_vals) if row.most_common_vals is not None else None,
                'most_common_freqs': str(row.most_common_freqs) if row.most_common_freqs is not None else None,
                'histogram_bounds': str(row.histogram_bounds) if row.histogram_bounds is not None else None,
                'correlation': float(row.correlation) if row.correlation is not None else None,
                'most_common_elems': str(row.most_common_elems) if row.most_common_elems is not None else None,
                'most_common_elem_freqs': str(row.most_common_elem_freqs) if row.most_common_elem_freqs is not None else None,
                'elem_count_histogram': str(row.elem_count_histogram) if row.elem_count_histogram is not None else None
            })
            
        stats_logger.debug(f"Captured {len(pg_stats_data)} rows from pg_stats")
        return pg_stats_data
        
    def _capture_pg_statistic(self, session: Session) -> List[Dict[str, Any]]:
        """
        Capture pg_statistic view data for public schema tables.
        
        Args:
            session: Database session for executing queries
            
        Returns:
            List of dictionaries containing pg_statistic data
        """
        pg_statistic_query = text("""
            SELECT 
                n.nspname as schemaname,
                c.relname as tablename,
                a.attname,
                s.stainherit as inherited,
                s.stanullfrac as null_frac,
                s.stawidth as avg_width,
                s.stadistinct as n_distinct,
                s.stakind1, s.stakind2, s.stakind3, s.stakind4, s.stakind5,
                s.staop1, s.staop2, s.staop3, s.staop4, s.staop5,
                s.stacoll1, s.stacoll2, s.stacoll3, s.stacoll4, s.stacoll5,
                s.stanumbers1, s.stanumbers2, s.stanumbers3, s.stanumbers4, s.stanumbers5,
                s.stavalues1, s.stavalues2, s.stavalues3, s.stavalues4, s.stavalues5
            FROM pg_statistic s
            JOIN pg_attribute a ON s.starelid = a.attrelid AND s.staattnum = a.attnum
            JOIN pg_class c ON s.starelid = c.oid
            JOIN pg_namespace n ON c.relnamespace = n.oid
            WHERE n.nspname = 'public'
            ORDER BY n.nspname, c.relname, a.attname
        """)
        
        result = session.execute(pg_statistic_query)
        pg_statistic_data = []
        
        for row in result:
            pg_statistic_data.append({
                'schemaname': row.schemaname,
                'tablename': row.tablename,
                'attname': row.attname,
                'inherited': row.inherited,
                'null_frac': float(row.null_frac) if row.null_frac is not None else None,
                'avg_width': int(row.avg_width) if row.avg_width is not None else None,
                'n_distinct': float(row.n_distinct) if row.n_distinct is not None else None,
                'stakind1': int(row.stakind1) if row.stakind1 is not None else None,
                'stakind2': int(row.stakind2) if row.stakind2 is not None else None,
                'stakind3': int(row.stakind3) if row.stakind3 is not None else None,
                'stakind4': int(row.stakind4) if row.stakind4 is not None else None,
                'stakind5': int(row.stakind5) if row.stakind5 is not None else None,
                'staop1': int(row.staop1) if row.staop1 is not None else None,
                'staop2': int(row.staop2) if row.staop2 is not None else None,
                'staop3': int(row.staop3) if row.staop3 is not None else None,
                'staop4': int(row.staop4) if row.staop4 is not None else None,
                'staop5': int(row.staop5) if row.staop5 is not None else None,  
                'stacoll1': int(row.stacoll1) if row.stacoll1 is not None else None,
                'stacoll2': int(row.stacoll2) if row.stacoll2 is not None else None,
                'stacoll3': int(row.stacoll3) if row.stacoll3 is not None else None,
                'stacoll4': int(row.stacoll4) if row.stacoll4 is not None else None,
                'stacoll5': int(row.stacoll5) if row.stacoll5 is not None else None,
                'stanumbers1': str(row.stanumbers1) if row.stanumbers1 is not None else None,
                'stanumbers2': str(row.stanumbers2) if row.stanumbers2 is not None else None,
                'stanumbers3': str(row.stanumbers3) if row.stanumbers3 is not None else None,
                'stanumbers4': str(row.stanumbers4) if row.stanumbers4 is not None else None,
                'stanumbers5': str(row.stanumbers5) if row.stanumbers5 is not None else None,
                'stavalues1': str(row.stavalues1) if row.stavalues1 is not None else None,
                'stavalues2': str(row.stavalues2) if row.stavalues2 is not None else None,
                'stavalues3': str(row.stavalues3) if row.stavalues3 is not None else None,
                'stavalues4': str(row.stavalues4) if row.stavalues4 is not None else None,
                'stavalues5': str(row.stavalues5) if row.stavalues5 is not None else None
            })
            
        stats_logger.debug(f"Captured {len(pg_statistic_data)} rows from pg_statistic")
        return pg_statistic_data
        
    def parse_statistics_snapshot(self, snapshot_json: str) -> Optional[List[Dict[str, Any]]]:
        """
        Parse a statistics snapshot JSON string back to data.
        
        Args:
            snapshot_json: JSON string containing statistics data
            
        Returns:
            Parsed statistics data or None if parsing fails
        """
        try:
            return json.loads(snapshot_json)
        except (json.JSONDecodeError, TypeError) as e:
            stats_logger.error(f"Failed to parse statistics snapshot: {str(e)}")
            return None 